{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:BlueViolet\"> Experiment 1: </h1>\n",
    "\n",
    "---\n",
    "Validation was run on the model sequentially for CompactCNN on the port \n",
    "127.0.0.1:8001 (local) over the course of several hours. \n",
    "The accuracy was better than expected given the implementation of batch \n",
    "normalization was not yet correct. \n",
    "\n",
    "Given baseline experiments with varied batch sizes, and the implementation \n",
    "used for this model, I expected an accuracy of around $0.50318$. However,\n",
    "the model actually achieved an accuracy of $0.53503$ with $168$ correct predictions\n",
    "out of $314$ samples. The sample-by-sample results can be viewed in the attached\n",
    "file \"classification_results_exp_1.txt\"\n",
    "\n",
    "The model used to achieve this initial result was one which contained the \n",
    "folded convolution parameters - *excluding the batch mean and variance*\n",
    "$$w_{fold} = \\gamma \\cdot \\frac{W}{\\sqrt{\\sigma^{2} + \\epsilon}} \\\\\n",
    "  b_{fold} = \\gamma \\cdot \\frac{b-\\mu}{\\sqrt{\\sigma^{2} + \\epsilon}} + \\beta$$ \n",
    "\n",
    "In other words, the weights used in this experiment had fold parameters corresponding to the following equation: \n",
    "$$w_{fold} = \\gamma \\cdot W \\\\\n",
    "  b_{fold} = \\gamma \\cdot b + \\beta$$\n",
    "\n",
    "See the following link for more information about the [transformation](https://nathanhubens.github.io/posts/deep%20learning/2020/04/20/BN.html)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
