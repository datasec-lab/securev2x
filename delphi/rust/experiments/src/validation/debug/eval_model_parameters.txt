conv.weight         :tensor([[[[ 0.1541,  0.0068, -0.1535,  ..., -0.1245, -0.0827, -0.0185]]],


        [[[-0.2573, -0.2386, -0.1482,  ..., -0.2197, -0.1804, -0.1997]]],


        [[[-0.2825, -0.3358, -0.3393,  ..., -0.3088, -0.1363, -0.1593]]],


        ...,


        [[[-0.2616, -0.2422, -0.0046,  ..., -0.1069, -0.3094, -0.2226]]],


        [[[ 0.2232,  0.1636,  0.2313,  ..., -0.0640, -0.1875, -0.1250]]],


        [[[ 0.0343,  0.1281,  0.0626,  ...,  0.3576,  0.5112,  0.2810]]]],
       device='cuda:0', dtype=torch.float64)
size                :torch.Size([32, 1, 1, 64])

====================================================================================================
conv.bias           :tensor([ 0.1028, -0.0112,  0.0923,  0.0122,  0.0168,  0.0591,  0.1129,  0.0195,
        -0.0291,  0.0768,  0.1165, -0.1197, -0.0837,  0.0652, -0.0983,  0.0131,
        -0.0139,  0.0268,  0.0830,  0.0448, -0.0583, -0.0011,  0.0447, -0.0282,
         0.0644, -0.1216,  0.0921, -0.0233,  0.0492,  0.0452,  0.1020, -0.0479],
       device='cuda:0', dtype=torch.float64)
size                :torch.Size([32])

====================================================================================================
batch.gamma         :tensor([[[[ 0.1131]],

         [[ 0.5895]],

         [[-0.5448]],

         [[ 0.4557]],

         [[-0.6496]],

         [[-0.6134]],

         [[ 0.2124]],

         [[-0.0040]],

         [[-0.0067]],

         [[-0.5373]],

         [[ 0.6869]],

         [[ 0.4724]],

         [[-0.5943]],

         [[ 0.3999]],

         [[ 0.6364]],

         [[-0.2058]],

         [[-0.3992]],

         [[ 0.0019]],

         [[ 0.2388]],

         [[ 0.2318]],

         [[ 0.1696]],

         [[-0.5480]],

         [[-0.4137]],

         [[-0.5571]],

         [[-0.3136]],

         [[ 0.6122]],

         [[-0.3288]],

         [[-0.0045]],

         [[-0.2164]],

         [[-0.1637]],

         [[ 0.5738]],

         [[ 0.3086]]]], device='cuda:0', dtype=torch.float64)
size                :torch.Size([1, 32, 1, 1])

====================================================================================================
batch.beta          :tensor([[[[ 0.0732]],

         [[-0.1094]],

         [[-0.1220]],

         [[ 0.2814]],

         [[-0.0982]],

         [[-0.0934]],

         [[-0.3564]],

         [[-0.1176]],

         [[-0.0847]],

         [[-0.0907]],

         [[-0.1321]],

         [[ 0.2794]],

         [[-0.0994]],

         [[-0.2840]],

         [[-0.1086]],

         [[-0.3372]],

         [[ 0.2808]],

         [[-0.1687]],

         [[-0.3923]],

         [[ 0.2388]],

         [[-0.2895]],

         [[-0.1215]],

         [[ 0.1752]],

         [[-0.0906]],

         [[-0.0565]],

         [[-0.0803]],

         [[ 0.3012]],

         [[-0.0779]],

         [[ 0.2547]],

         [[-0.2699]],

         [[-0.1010]],

         [[ 0.2893]]]], device='cuda:0', dtype=torch.float64)
size                :torch.Size([1, 32, 1, 1])

====================================================================================================
fc.weight           :tensor([[ 0.1435, -0.6405, -0.3455,  0.3536, -0.6309, -0.6284,  0.4125, -0.0535,
          0.1114, -0.4295, -0.5014,  0.2221, -0.6731,  0.5798, -0.5454,  0.5347,
          0.2960, -0.0827,  0.5344,  0.3215,  0.3907, -0.4617,  0.2596, -0.4040,
         -0.2128, -0.5960,  0.3914, -0.0887,  0.3395,  0.3017, -0.3480,  0.3587],
        [-0.0011,  0.6137,  0.4915, -0.2065,  0.5958,  0.6457, -0.5138,  0.0196,
          0.1181,  0.5024,  0.7502, -0.4229,  0.5427, -0.5193,  0.7456, -0.5577,
         -0.3966, -0.0190, -0.4438, -0.1710, -0.2643,  0.5110, -0.4094,  0.6083,
          0.2731,  0.6895, -0.3710, -0.0755, -0.0277, -0.4601,  0.6981, -0.3840]],
       device='cuda:0', dtype=torch.float64)
size                :torch.Size([2, 32])

====================================================================================================
fc.bias             :tensor([ 0.2050, -0.2084], device='cuda:0', dtype=torch.float64)
size                :torch.Size([2])

====================================================================================================